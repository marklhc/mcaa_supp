pnormmix <- function(q, mean1 = 0, sd1 = 1, mean2 = 0, sd2 = 1, pmix1 = 0.5, 
                     lower.tail = TRUE) {
  # Distribution function (pdf) of a mixture of two normal distributions. 
  #
  # Args:
  #   q: vector of quantiles.
  #   mean1: mean of first normal distribution.
  #   sd1: standard deviation of first normal distribution.
  #   mean2: mean of second normal distribution.
  #   sd2: standard deviation of second normal distribution.
  #   pmix1: mixing proportion for the first distribution. Should be a 
  #          number in the range (0, 1).
  #   lower.tail: logical; if TRUE(default), probabilities are P[X <= x]; 
  #               otherwise, P[X > x]. 
  #
  #   Returns:
  #     Cumulative probability of q or 1 minus it on the mixture normal 
  #     distribution.
  # Error handling
  stopifnot(pmix1 > 0, pmix1 < 1)
  as.vector(c(pmix1, 1 - pmix1) %*% 
              sapply(q, pnorm, mean = c(mean1, mean2), sd = c(sd1, sd2), 
                     lower.tail = lower.tail))
}

# test
pnormmix(1, 0, 3.1, 1.7, 3.1, lower.tail = FALSE)

qnormmix <- function(p, mean1 = 0, sd1 = 1, mean2 = 0, sd2 = 1, pmix1 = 0.5, 
                     lower.tail = TRUE) {
  # Quantile function of a mixture of two normal distributions. 
  #
  # Args:
  #   p: vector of probabilities.
  #   mean1: mean of first normal distribution.
  #   sd1: standard deviation of first normal distribution.
  #   mean2: mean of second normal distribution.
  #   sd2: standard deviation of second normal distribution.
  #   pmix1: mixing proportion for the first distribution. Should be a 
  #          number in the range (0, 1).
  #   lower.tail: logical; if TRUE(default), probabilities are P[X <= x]; 
  #               otherwise, P[X > x]. 
  #
  #   Returns:
  #     Quantile corresponding to p or 1 - p on the mixture normal 
  #     distribution.
  # Error handling
  stopifnot(pmix1 > 0, pmix1 < 1, p >= 0, p <= 1)
  f <- function(x) (pnormmix(x, mean1, sd1, mean2, sd2, pmix1, 
                             lower.tail) - p)^2
  start <- as.vector(c(pmix1, 1 - pmix1) %*% 
                       sapply(p, qnorm, c(mean1, mean2), c(sd1, sd2), 
                              lower.tail = lower.tail))
  nlminb(start, f)$par
}

.bvnorm_kernel <- function(x, y, mu_x = 0, mu_y = 0, sd_x = 1, sd_y = 1, 
                           cov_xy = 0) {
  # Helper funcction for computing the kernel for bivariate normal density
  cor <- cov_xy / sd_x / sd_y
  numer <- (x - mu_x)^2 / sd_x^2 + (y - mu_y)^2 / sd_y^2 - 
    2 * cor * (x - mu_x) * (y - mu_y) / sd_x / sd_y
  numer / (1 - cor^2)
}

contour_bvnorm <- function(mean1 = 0, sd1 = 1, mean2 = 0, sd2 = 1, 
                           cor12 = 0, cov12 = NULL, 
                           density = .95, length_out = 101, 
                           bty = "L", 
                           ...) {
  # Plot contour for a bivariate normal distribution
  #
  # Args:
  #   mean1: mean of first normal distribution (on x-axis).
  #   sd1: standard deviation of first normal distribution.
  #   mean2: mean of second normal distribution (on y-axis).
  #   sd2: standard deviation of second normal distribution.
  #   cor12: correlation in the bivariate normal.
  #   cov12: covariance in the bivariate normal. If not input, compute the
  #          covariance using the correlation and the standard deviations.
  #   density: density level, i.e., probability enclosed by the ellipse.
  #   length_out: number of values on the x-axis and on the y-axis to be
  #               evaluated; default to 101.
  #   bty: argument passed to the `contour` function.
  #   ...: other arguments passed to the `countour` funcction.
  #
  #   Returns:
  #     a plot showing the contour of the bivariate normal distribution on 
  #     a two-dimensional space.
  # Error handling
  stopifnot(cor12 >= -1, cor12 <= 1)
  if (is.null(cov12)) cov12 <- cor12 * sd1 * sd2s
  x_seq <- mean1 + seq(-3, 3, length.out = length_out) * sd1
  y_seq <- mean2 + seq(-3, 3, length.out = length_out) * sd2
  z <- outer(x_seq, y_seq, .bvnorm_kernel, mu_x = mean1, mu_y = mean2, 
             sd_x = sd1, sd_y = sd2, cov_xy = cov12)
  contour(x_seq, y_seq, z, levels = qchisq(density, 2), drawlabels = FALSE, 
          bty = bty, ...)
}

.partit_bvnorm <- function(cut1, cut2, mean1 = 0, sd1 = 1, mean2 = 0, sd2 = 1, 
                           cor12 = 0, cov12 = cor12 * sd1 * sd2) {
  # Helper funcction for computing summary statistics from a selection approach
  Sigma <- matrix(c(sd1^2, cov12, cov12, sd2^2), nrow = 2)
  C <- pmnorm(c(cut1, cut2), c(mean1, mean2), Sigma)
  B <- pnorm(cut1, mean1, sd1) - C
  D <- pnorm(cut2, mean2, sd2) - C
  A <- 1 - B - C - D
  propsel <- A + B
  success_ratio <- A / propsel
  sensitivity <- A / (A + D)
  specificity <- C / (C + B)
  c(A, B, C, D, propsel, success_ratio, sensitivity, specificity)
}

## Partial Invariance Function for weighted sums 
PartInv_we <- function(propsel, cut_z = NULL, c, kappa_r, kappa_f = kappa_r, 
                       phi_r, phi_f = phi_r, lambda_r, lambda_f = lambda_r, 
                       Theta_r, Theta_f = Theta_r, tau_r, tau_f = tau_r, 
                       pmix_ref = 0.5, plot_contour = TRUE, ...) {
  # Evaluate partial measurement invariance using Millsap & Kwok's (2004) 
  # approach
  #
  # Args:
  #   propsel: proportion of selection. If missing, computed using `cut_z`.
  #   cut_z: prespecified cutoff score on the observed composite. This argument
  #          is ignored when `propsel` has input.
  #   c: a vector of weight for each items 
  #   kappa_r: latent factor mean for the reference group.
  #   kappa_f: (optional) latent factor mean for the focal group; 
  #            if no input, set equal to kappa_r.
  #   phi_r: latent factor variance for the reference group.
  #   phi_f: (optional) latent factor variance for the focal group; 
  #          if no input, set equal to phi_r.
  #   lambda_r: a vector of factor loadings for the reference group.
  #   lambda_f: (optional) a vector of factor loadings for the focal group; 
  #             if no input, set equal to lambda_r.
  #   tau_r: a vector of measurement intercepts for the reference group.
  #   tau_f: (optional) a vector of measurement intercepts for the focal group; 
  #          if no input, set equal to tau_r.
  #   Theta_r: a matrix of the unique factor variances and covariances 
  #            for the reference group.
  #   Theta_f: (optional) a matrix of the unique factor variances and 
  #            covariances for the focal group; 
  #            if no input, set equal to Theta_r.
  #   pmix_ref: Proportion of the reference group; 
  #             default to 0.5 (i.e., two populations have equal size).
  #   plot_contour: logical; whether the contour of the two populations 
  #                 should be plotted; default to TRUE.
  #   ...: other arguments passed to the `countour` funcction.
  #
  #   Returns:
  #     a list of four elements and a plot if plot_contour == TRUE:
  #     - propsel: echo the same argument as input.
  #     - cutpt_xi: cut point on the latent scale (xi).
  #     - cutpt_z: cut point on the observed scale (Z).
  #     - summary: A 8 x 2 table, with columns representing the reference
  #                and the focal groups, and the rows represent
  #                probabilities of true positive (A), false positive (B), 
  #                true negative (C), false negative (D); proportion selected, 
  #                success ratio, sensitivity, and specificity. 
  # Error handling
  stopifnot(length(kappa_r) == 1, length(kappa_f) == 1, length(phi_r) == 1, 
            length(phi_f) == 1)
  if (length(Theta_r) == length(lambda_r)) Theta_r <- diag(Theta_r)
  if (length(Theta_f) == length(lambda_f)) Theta_f <- diag(Theta_f)
  library(mnormt)  # load `mnormt` package
  # mean_zr <- c * sum(tau_r) + c * sum(lambda_r) * kappa_r
  # mean_zf <- c * sum(tau_f) + c * sum(lambda_f) * kappa_f
  # sd_zr <- sqrt(sum(c * lambda_r)^2 * phi_r  + (c ^ 2) * sum(Theta_r))
  # sd_zf <- sqrt(sum(c * lambda_f)^2 * phi_f + (c ^ 2) * sum(Theta_f ))
  # cov_z_xir <- c * sum(lambda_r) * phi_r
  # cov_z_xif <- c * sum(lambda_f) * phi_f
  mean_zr <- sum(c * tau_r) + sum(c * lambda_r) * kappa_r
  mean_zf <- sum(c * tau_f)+ sum(c * lambda_f) * kappa_f
  sd_zr <- sqrt(sum(lambda_r * c)^2 * phi_r  + sum(Theta_r * (c^2)))
  sd_zf <- sqrt(sum(lambda_f * c)^2 * phi_f + sum(Theta_f * (c^2)))
  cov_z_xir <- sum(lambda_r * c) * phi_r
  cov_z_xif <- sum(lambda_f * c) * phi_f
  sd_xir <- sqrt(phi_r)
  sd_xif <- sqrt(phi_f)
  if (!missing(propsel)) {
    if (!is.null(cut_z)) {
      warning("Input to `cut_z` is ignored.")
    }
    cut_z <- qnormmix(propsel, mean_zr, sd_zr, mean_zf, sd_zf, 
                      pmix_ref, lower.tail = FALSE)
  } else if (!is.null(cut_z) & missing(propsel)) {
    propsel <- pnormmix(cut_z, mean_zr, sd_zr, mean_zf, sd_zf, 
                        pmix_ref, lower.tail = FALSE)
  }
  cut_xi <- qnormmix(propsel, kappa_r, sd_xir, kappa_f, sd_xif, 
                     pmix_ref, lower.tail = FALSE)
  partit_1 <- .partit_bvnorm(cut_xi, cut_z, kappa_r, sd_xir, mean_zr, sd_zr, 
                             cov12 = cov_z_xir)
  partit_2 <- .partit_bvnorm(cut_xi, cut_z, kappa_f, sd_xif, mean_zf, sd_zf, 
                             cov12 = cov_z_xif)
  # selection indices for the focal group if latent dist matches the reference
  mean_zref <- sum(c * tau_f) + sum(c * lambda_f) * kappa_r
  sd_zref <- sqrt(sum(lambda_f * c)^2 * phi_r  + sum(Theta_f * (c^2)))
  cov_z_xiref <- sum(lambda_f * c) * phi_r
  partit_1e2 <- .partit_bvnorm(cut_xi, cut_z, 
                               kappa_r, sd_xir, mean_zref, 
                               sd_zref, 
                               cov12 = cov_z_xiref)
  dat <- data.frame("Reference" = partit_1, "Focal" = partit_2, 
                    "E_R(Focal)" = partit_1e2, 
                    row.names = c("A (true positive)", "B (false positive)", 
                                  "C (true negative)", "D (false negative)", 
                                  "Proportion selected", "Success ratio", 
                                  "Sensitivity", "Specificity"))
  p <- NULL
  if (plot_contour) {
    x_lim <- range(c(kappa_r + c(-3, 3) * sd_xir, 
                     kappa_f + c(-3, 3) * sd_xif))
    y_lim <- range(c(mean_zr + c(-3, 3) * sd_zr, 
                     mean_zf + c(-3, 3) * sd_zf))
    contour_bvnorm(kappa_r, sd_xir, mean_zr, sd_zr, cov12 = cov_z_xir, 
                   xlab = bquote("Latent Score" ~ (xi)), 
                   ylab = bquote("Observed Composite" ~ (italic(Z))), 
                   lwd = 2, col = "red", xlim = x_lim, ylim = y_lim, 
                   ...)
    contour_bvnorm(kappa_f, sd_xif, mean_zf, sd_zf, cov12 = cov_z_xif, 
                   add = TRUE, lty = "dashed", lwd = 2, col = "blue", 
                   ...)
    legend("topleft", c("Reference group", "Focal group"), 
           lty = c("solid", "dashed"), col = c("red", "blue"))
    abline(h = cut_z, v = cut_xi)
    x_cord <- rep(cut_xi + c(.25, -.25) * sd_xir, 2)
    y_cord <- rep(cut_z + c(.25, -.25) * sd_zr, each = 2)
    text(x_cord, y_cord, c("A", "B", "D", "C"))
    p <- recordPlot()
  }
  list(propsel = propsel, cutpt_xi = cut_xi, cutpt_z = cut_z, 
       summary = round(dat, 3), 
       ai_ratio = dat["Proportion selected", 3] / 
         dat["Proportion selected", 1], 
       p = p)
}
# PartInv_we(.10, c = c(1, 1, 1, 1), 
#            kappa_r = 0.5, kappa_f = 0, phi_r = 1,
#            lambda_r = c(.3, .5, .9, .7), tau_r = c(.225, .025, .010, .240),
#            tau_f = c(.225, -.05, .240, -.025),
#            Theta_r = diag(.96, 4))
# 
# PartInv(propsel = .25, kappa_r = 0.5, kappa_f = 0, phi_r = 1, 
#         lambda_r = c(.3, .5, .9, .7), lambda_f = c(.3, .5, .7, .5),
#         tau_r = c(.225, .025, .010, .240), tau_f = c(.225, -0.225, .240, -.025), 
#         Theta_r = diag(.96, 4))

## with AI and extend to multidimensional framework

PartInvMulti_we <- function(propsel, cut_z = NULL, weights_item, weights_latent,
                            alpha_r, alpha_f = alpha_r, psi_r, psi_f = psi_r,
                            lambda_r, lambda_f = lambda_r,nu_r, nu_f = nu_r,
                            Theta_r, Theta_f = Theta_r, 
                            pmix_ref = 0.5, plot_contour = TRUE, ...) {
  # Evaluate partial measurement invariance using Millsap & Kwok's (2004) 
  # approach
  #
  # Args:
  #   propsel: proportion of selection. If missing, computed using `cut_z`.
  #   cut_z: prespecified cutoff score on the observed composite. This argument
  #          is ignored when `propsel` has input.
  #   weights_item: a vector of item weights
  #   weights_latent: a  vector of latent factor weights
  #   alpha_r: a vector of latent factor mean for the reference group.
  #   alpha_f: (optional) a vector of latent factor mean for the focal group; 
  #            if no input, set equal to alpha_r.
  #   psi_r: a matrix of latent factor variance for the reference group.
  #   psi_f: (optional) a matrix of latent factor variance for the focal group; 
  #          if no input, set equal to psi_r.
  #   lambda_r: a matrix of factor loadings for the reference group.
  #   lambda_f: (optional) a matrix of factor loadings for the focal group; 
  #             if no input, set equal to lambda_r.
  #   nu_r: a matrix of measurement intercepts for the reference group.
  #   nu_f: (optional) a matrix of measurement intercepts for the focal group; 
  #          if no input, set equal to nu_r.
  #   Theta_r: a matrix of the unique factor variances and covariances 
  #            for the reference group.
  #   Theta_f: (optional) a matrix of the unique factor variances and 
  #            covariances for the focal group; 
  #            if no input, set equal to Theta_r.
  #   pmix_ref: Proportion of the reference group; 
  #             default to 0.5 (i.e., two populations have equal size).
  #   plot_contour: logical; whether the contour of the two populations 
  #                 should be plotted; default to TRUE.
  #   ...: other arguments passed to the `countour` function.
  #
  #   Returns:
  #     a list of four elements and a plot if plot_contour == TRUE:
  #     - propsel: echo the same argument as input.
  #     - cutpt_xi: cut point on the latent scale (xi).
  #     - cutpt_z: cut point on the observed scale (Z).
  #     - summary: A 8 x 2 table, with columns representing the reference
  #                and the focal groups, and the rows represent
  #                probabilities of true positive (A), false positive (B), 
  #                true negative (C), false negative (D); proportion selected, 
  #                success ratio, sensitivity, and specificity. 
  # Error handling
  stopifnot(length(alpha_r) != 1, length(alpha_f) != 1, length(psi_r) != 1, 
            length(psi_f) != 1)
  if (length(Theta_r) <= length(lambda_r)) Theta_r <- diag(Theta_r)
  if (length(Theta_f) <= length(lambda_f)) Theta_f <- diag(Theta_f)
  if(is.matrix(weights_item) == FALSE) weights_item <- t(weights_item)
  if(is.matrix(weights_latent) == FALSE) weights_latent <- t(weights_latent)
  if(is.matrix(alpha_r) == FALSE) alpha_r <- as.matrix(alpha_r)
  if(is.matrix(alpha_f) == FALSE) alpha_f <- as.matrix(alpha_f)
  library(mnormt)  # load `mnormt` package
  mean_zr <- as.numeric(weights_item %*% nu_r + weights_item %*% lambda_r %*% alpha_r)
  mean_zf <- as.numeric(weights_item %*% nu_f + weights_item %*% lambda_f %*% alpha_f)
  sd_zr <- as.numeric(sqrt(weights_item %*% lambda_r %*% psi_r %*% t(weights_item %*% lambda_r)+ weights_item %*% Theta_r %*% t(weights_item)))
  sd_zf <- as.numeric(sqrt(weights_item %*% lambda_f %*% psi_f %*% t(weights_item %*% lambda_f)+ weights_item %*% Theta_f %*% t(weights_item)))
  cov_z_xir <- as.numeric(weights_item %*% lambda_r %*% psi_r %*% t(weights_latent))
  cov_z_xif <- as.numeric(weights_item %*% lambda_f %*% psi_f %*% t(weights_latent))
  sd_xir <- as.numeric(sqrt(weights_latent %*% psi_r %*% t(weights_latent)))
  sd_xif <- as.numeric(sqrt(weights_latent %*% psi_f %*% t(weights_latent)))
  zeta_r <- as.numeric(weights_latent%*%alpha_r)
  zeta_f <- as.numeric(weights_latent%*%alpha_f)
  if (!missing(propsel)) {
    if (!is.null(cut_z)) {
      warning("Input to `cut_z` is ignored.")
    }
    cut_z <- qnormmix(propsel, mean_zr, sd_zr, mean_zf, sd_zf, 
                      pmix_ref, lower.tail = FALSE)
  } else if (!is.null(cut_z) & missing(propsel)) {
    propsel <- pnormmix(cut_z, mean_zr, sd_zr, mean_zf, sd_zf, 
                        pmix_ref, lower.tail = FALSE)
  }
  cut_xi <- qnormmix(propsel, zeta_r, sd_xir,zeta_f, sd_xif,
                     pmix_ref, lower.tail = FALSE)
  partit_1 <- .partit_bvnorm(cut_xi, cut_z, zeta_r, sd_xir, mean_zr, sd_zr, 
                             cov12 = cov_z_xir)
  partit_2 <- .partit_bvnorm(cut_xi, cut_z, zeta_f, sd_xif, mean_zf, sd_zf, 
                             cov12 = cov_z_xif)
  # selection indices for the focal group if latent dist matches the reference
  mean_zref <- as.numeric(weights_item %*% nu_f + weights_item %*% lambda_f %*% alpha_r)
  sd_zref <- as.numeric(sqrt(weights_item %*% lambda_f %*% psi_r %*% t(weights_item %*% lambda_f)+ weights_item %*% Theta_f %*% t(weights_item)))
  cov_z_xiref <- as.numeric(weights_item %*% lambda_f %*% psi_r %*% t(weights_latent))
  partit_1e2 <- .partit_bvnorm(cut_xi, cut_z, 
                               zeta_r, sd_xir, mean_zref, 
                               sd_zref, 
                               cov12 = cov_z_xiref)
  
  dat <- data.frame("Reference" = partit_1, "Focal" = partit_2, 
                    "E_R(Focal)" = partit_1e2, 
                    row.names = c("A (true positive)", "B (false positive)", 
                                  "C (true negative)", "D (false negative)", 
                                  "Proportion selected", "Success ratio", 
                                  "Sensitivity", "Specificity"))
  p <- NULL
  if (plot_contour) {
    x_lim <- range(c(zeta_r + c(-3, 3) * sd_xir, 
                     zeta_f + c(-3, 3) * sd_xif))
    y_lim <- range(c(mean_zr + c(-3, 3) * sd_zr, 
                     mean_zf + c(-3, 3) *sd_zf))
    contour_bvnorm(zeta_r, sd_xir, mean_zr, sd_zr, cov12 = cov_z_xir, 
                   xlab = bquote("Latent Composite" ~ (zeta)), 
                   ylab = bquote("Observed Composite" ~ (italic(Z))), 
                   lwd = 2, col = "red", xlim = x_lim, ylim = y_lim, 
                   ...)
    contour_bvnorm(zeta_f, sd_xif, mean_zf, sd_zf, cov12 = cov_z_xif, 
                   add = TRUE, lty = "dashed", lwd = 2, col = "blue", 
                   ...)
    legend("topleft", c("Reference group", "Focal group"), 
           lty = c("solid", "dashed"), col = c("red", "blue"))
    abline(h = cut_z, v = cut_xi)
    x_cord <- rep(cut_xi + c(.25, -.25) * sd_xir, 2)
    y_cord <- rep(cut_z + c(.25, -.25) * sd_zr, each = 2)
    text(x_cord, y_cord, c("A", "B", "D", "C"))
    p <- recordPlot()
  }
  list(propsel = propsel, cutpt_xi = cut_xi, cutpt_z = cut_z, 
       summary = round(dat, 3), 
       ai_ratio = dat["Proportion selected", 3] / 
         dat["Proportion selected", 1], p = p)
}

# PartInvMulti_we(propsel = .05,
#                 weights_item = c(1/4, 1/4, 1/6, 1/6, 1/6), 
#                 weights_latent = c(0.5, 0.5), 
#                 alpha_r = c(0, 0), 
#                 alpha_f = c(-0.3, 0.1), 
#                 psi_r = matrix(c(1, 0.5, 0.5, 1), nrow = 2),
#                 lambda_r = lambda_matrix, 
#                 nu_r = c(.225, .025, .010, .240, .125),
#                 nu_f = c(.225, -.05, .240, -.025, .125),
#                 Theta_r = diag(1, 5), 
#                 Theta_f = c(1, .95, .80, .75, 1))
